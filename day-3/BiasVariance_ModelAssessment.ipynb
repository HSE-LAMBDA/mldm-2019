{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiasVariance_ModelAssessment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/mldm-2019/blob/master/day-3/BiasVariance_ModelAssessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecjpqpMok8eh",
        "colab_type": "text"
      },
      "source": [
        "# Bias-Variance decomposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtlnBa24uv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPl1NddU45kV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def true_dep(x):\n",
        "  return np.cos((x - 0.2)**2) + 0.2 / (1 + 50 * (x - 0.3)**2)\n",
        "\n",
        "x_true = np.linspace(0, 1, 100)\n",
        "y_true = true_dep(x_true)\n",
        "\n",
        "def generate_n_datasets(num_datasets, dataset_length, noise_power=0.02):\n",
        "  shape = (num_datasets, dataset_length, 1)\n",
        "  x = np.random.uniform(size=shape)\n",
        "  y = true_dep(x) + np.random.normal(scale=noise_power, size=shape)\n",
        "  return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMq2dk0b7KAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = generate_n_datasets(1, 30)\n",
        "plt.scatter(x.squeeze(), y.squeeze(), s=20, c='orange')\n",
        "plt.plot(x_true, y_true, c='c', linewidth=1.5);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmhwKmCb9IGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rWsmqAu8NDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_bias2_variance(model, datasets_X, datasets_y):\n",
        "  preds = []\n",
        "  for X, y in tqdm(zip(datasets_X, datasets_y), total=len(datasets_X)):\n",
        "    m = deepcopy(model)\n",
        "    m.fit(X, y)\n",
        "    preds.append(m.predict(x_true[:,np.newaxis]).squeeze())\n",
        "  preds = np.array(preds)\n",
        "  mean_pred = preds.mean(axis=0)\n",
        "  bias2 = (y_true - mean_pred)**2\n",
        "  variance = ((preds - mean_pred[np.newaxis,...])**2).mean(axis=0)\n",
        "\n",
        "  return bias2, variance, preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO6xg7VB-fg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zerleLK-pvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "powers = np.arange(1, 9)\n",
        "\n",
        "bias2, variance, preds = [], [], []\n",
        "for p in powers:\n",
        "  model = Pipeline([\n",
        "      ('poly', PolynomialFeatures(degree=p)),\n",
        "      ('linear', LinearRegression())\n",
        "  ])\n",
        "\n",
        "  b2, v, p = calc_bias2_variance(model, *generate_n_datasets(10000, 30))\n",
        "  bias2.append(b2)\n",
        "  variance.append(v)\n",
        "  preds.append(p)\n",
        "\n",
        "bias2 = np.array(bias2)\n",
        "variance = np.array(variance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvTGdDn6hJ5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ncols = 4\n",
        "nrows = int(np.ceil(len(powers) / ncols))\n",
        "\n",
        "plt.figure(figsize=(18, 3.5 * nrows))\n",
        "\n",
        "yrange = y_true.max() - y_true.min()\n",
        "\n",
        "for i, (pred, pow) in tqdm(enumerate(zip(preds, powers), 1)):\n",
        "  plt.subplot(nrows, ncols, i)\n",
        "  for p in pred[np.random.choice(len(pred), size=200, replace=False)]:\n",
        "    plt.plot(x_true, p, linewidth=0.05, c='b');\n",
        "  plt.plot(x_true, y_true, linewidth=3, label='Truth', c='r')\n",
        "  plt.ylim(y_true.min() - 0.5 * yrange, y_true.max() + 0.5 * yrange)\n",
        "  plt.title('power = {}'.format(pow))\n",
        "  plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCYG8jE6fxf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(powers, bias2.mean(axis=1), label='bias^2')\n",
        "plt.plot(powers, variance.mean(axis=1), label='variance')\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.xlabel('power');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvr8rwXo-_Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(18, 15))\n",
        "iplot = 1\n",
        "for i in range(0, bias2.shape[1], 10):\n",
        "  plt.subplot(4, 3, iplot); iplot += 1\n",
        "  plt.plot(powers, bias2[:,i], label='bias^2')\n",
        "  plt.plot(powers, variance[:,i], label='variance')\n",
        "  plt.legend()\n",
        "  plt.yscale('log')\n",
        "  plt.xlabel('power');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FADHpOdKaOGv",
        "colab_type": "text"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfazUP1LlEwU",
        "colab_type": "text"
      },
      "source": [
        "# Notes on Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeNozS9_aH7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 50\n",
        "p = 1000\n",
        "\n",
        "n_cv = 5\n",
        "\n",
        "num_best_features = 100\n",
        "n_neighbors = 1\n",
        "\n",
        "n_experiments = 100\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def run_experiment():\n",
        "  X = np.random.normal(size=(N, p))\n",
        "  y = np.random.randint(2, size=N)\n",
        "\n",
        "  abs_cov = np.abs(((X - X.mean(axis=0)) * ((y - y.mean())[:,np.newaxis])).sum(axis=0))\n",
        "  best_features = np.argsort(abs_cov)[-num_best_features:]\n",
        "  X_best = X[:,best_features]\n",
        "  \n",
        "  kf = KFold(n_splits=n_cv)\n",
        "\n",
        "  model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "  cv_errors = []\n",
        "  for i_train, i_test in kf.split(X_best):\n",
        "    model.fit(X_best[i_train], y[i_train])\n",
        "    cv_errors.append(accuracy_score(y[i_test], model.predict(X_best[i_test])))\n",
        "  \n",
        "  return np.mean(cv_errors)\n",
        "\n",
        "\n",
        "results = [run_experiment() for _ in trange(n_experiments)]\n",
        "\n",
        "plt.hist(results, bins=10);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK61NzKWf8xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_experiment_2():\n",
        "  X = np.random.normal(size=(N, p))\n",
        "  y = np.random.randint(2, size=N)\n",
        "  \n",
        "  kf = KFold(n_splits=n_cv)\n",
        "\n",
        "  model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "  cv_errors = []\n",
        "  for i_train, i_test in kf.split(X):\n",
        "    abs_cov = np.abs(((X[i_train] - X[i_train].mean(axis=0)) * \n",
        "                      ((y[i_train] - y[i_train].mean())[:,np.newaxis])).sum(axis=0))\n",
        "    best_features = np.argsort(abs_cov)[-num_best_features:]\n",
        "    X_best = X[:,best_features]\n",
        "\n",
        "    model.fit(X_best[i_train], y[i_train])\n",
        "    cv_errors.append(accuracy_score(y[i_test], model.predict(X_best[i_test])))\n",
        "  \n",
        "  return np.mean(cv_errors)\n",
        "\n",
        "\n",
        "results = [run_experiment_2() for _ in trange(n_experiments)]\n",
        "\n",
        "plt.hist(results, bins=10);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IoXhaQt1wT5",
        "colab_type": "text"
      },
      "source": [
        "# Notes on Test error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbhst77E3tm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import clone"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OK55AW94E27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_data():\n",
        "  X, y = make_blobs(n_samples=20000, centers=[[0., 0.5], [1., 0.]])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.01)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = gen_data()\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "plt.scatter(*X_train.T, c=y_train);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHZ5yzJk1uIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_cv(model, X, y, error_func, n_cv=5):\n",
        "  kf = KFold(n_splits=n_cv)\n",
        "  errors = []\n",
        "  for i_train, i_test in kf.split(X):\n",
        "    m = clone(model)\n",
        "    m.fit(X[i_train], y[i_train])\n",
        "    errors.append(error_func(y[i_test], m.predict(X[i_test])))\n",
        "  model.fit(X, y)\n",
        "  return np.mean(errors)\n",
        "\n",
        "def error(y_true, y):\n",
        "  return 1. - accuracy_score(y_true, y)\n",
        "\n",
        "def true_vs_cv_error(model):\n",
        "  X_train, X_test, y_train, y_test = gen_data()\n",
        "  cv_error = run_cv(model, X_train, y_train, error)\n",
        "  true_error = error(y_test, model.predict(X_test))\n",
        "  return true_error, cv_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAlqyLtS99Wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPLJbBPi6iaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "errors = np.array([true_vs_cv_error(SVC(C=1., gamma='auto'))\n",
        "                   for _ in trange(100)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RFtnfrE65pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(*errors.T, s=3.);\n",
        "plt.xlim(0, 0.6)\n",
        "plt.ylim(0, 0.6);\n",
        "plt.xlabel(\"True error\")\n",
        "plt.ylabel(\"CV error\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZOwHihCZO8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}