{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction-to-TF2.0-seminar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/mldm-2019/blob/master/day-5/Introduction_to_TF2_0_seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVhH9wpNyl0Y",
        "colab_type": "text"
      },
      "source": [
        "# Brief intro to TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb3IWYPEyq3f",
        "colab_type": "text"
      },
      "source": [
        "![tf logo](https://www.tensorflow.org/images/tf_logo_social.png)\n",
        "\n",
        "TensorFlow (tf) is one of the popular symbolic math libraries. Roughly, you can think of it as (a subset of) `numpy` with *GPU support* and *automatic differentiation* + a set of useful tools to build and train neural nets.\n",
        "\n",
        "The computations in tf are represented in the form of computation graph - a directed graph whose edges are the *numerical values* (or 'tensors') to make calculations with, and whose vertices are operations on those values. The edge directions indicate the direction of the computation flow, i.e. what tensors are the inputs and what are the outputs to a given operation (vertex).\n",
        "\n",
        "Prior to the release of version 2.0, the main execution paradigm in tf was the *lazy evaluation*. This is an evaluation strategy that delays the execution of an operation until its result is actually needed. This means that in order to make computations you need to first define the computation graph and then execute it separately. While such an approach is reasonable for most NNs (you define the network architecture only once and then repeatedly feed the data to it) it might seem a little unintuitive. Also, this paradigm makes debugging quite troublesome. \n",
        "\n",
        "Starting from version 2.0, the default paradigm in tf is the *eager evaluation*, which runs the operations as soon as you create them. This approach might feel more natural and therefore make the development process smoother. It is still possible to use the lazy execution paradigm though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNnco085_svg",
        "colab_type": "text"
      },
      "source": [
        "Let's start this introduction with an overview of the low-level API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8494qv0QWozp",
        "colab_type": "text"
      },
      "source": [
        "## Low-level intro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98J01C9nPnhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this line ensures you use the new version of tensorflow:\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# tf.debugging.set_log_device_placement(True)\n",
        "        # uncommenting the previous line will let you peek on what's\n",
        "        # happening behind the scenes (i.e. what operations are\n",
        "        # created, which devices they are using, etc.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-5WIHKNBUZX",
        "colab_type": "text"
      },
      "source": [
        "### Basic stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-yBcC3MBKSC",
        "colab_type": "text"
      },
      "source": [
        "Firstly, consider the following code in `numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZy-qb0CuSAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1., 2., 3.])\n",
        "y = np.array([3., 2., 1.])\n",
        "\n",
        "print('---')\n",
        "print(x + y)\n",
        "\n",
        "print('---')\n",
        "print(x * y)\n",
        "\n",
        "print('---')\n",
        "print(x.dot(y))\n",
        "\n",
        "print('---')\n",
        "print(x[:,np.newaxis].dot(y[np.newaxis,:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUSKjjGIBaah",
        "colab_type": "text"
      },
      "source": [
        "Here's the equivalent in TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9xqixVdwGic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.convert_to_tensor([1., 2., 3.])\n",
        "y = tf.convert_to_tensor([3., 2., 1.])\n",
        "\n",
        "print('---')\n",
        "print(x + y)\n",
        "\n",
        "print('---')\n",
        "print(x * y)\n",
        "\n",
        "print('---')\n",
        "print(tf.matmul(x[tf.newaxis,:], y[:,tf.newaxis]))\n",
        "\n",
        "print('---')\n",
        "print(tf.matmul(x[:,tf.newaxis], y[tf.newaxis,:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H57DFr_hBtOX",
        "colab_type": "text"
      },
      "source": [
        "Like `numpy`, TensorFlow is capable of broadcasting unit dimentions, e.g. below we calculate a difference between two tensors of shapes `(3, 1)` and `(1, 3)` to get the result of shape `(3, 3)`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dc7HKp1uR14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = x[:,tf.newaxis] - y[tf.newaxis,:]\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr3k-vlyCC0N",
        "colab_type": "text"
      },
      "source": [
        "Actions like `mean`, `max`, `min`, etc. are implemented with the `reduce_*` opetations, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umwIlq08yH2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.reduce_sum(z, axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhppxvb_CUvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now try printing out the max of z along axis 1\n",
        "<YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb1rENaWDOgx",
        "colab_type": "text"
      },
      "source": [
        "Contrary to `numpy`, you cannot assign to tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En8WAyw5uRqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  z[1,1] = 3.\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsRU0jCaD-dp",
        "colab_type": "text"
      },
      "source": [
        "Tensors are immutable. If you wish to have a modifiable tensor, then you want to use the `tf.Variable`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNjPU-j5uRWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_var = tf.Variable(z)\n",
        "print(z_var)\n",
        "z_var[1,1].assign(3.)\n",
        "print(z_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPMaVtR7jEvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Excersize:\n",
        "# 1) create a normal random vector (tensorflow tensor) of size 5\n",
        "# 2) create a uniform random vector (tensorflow tensor) of size 5\n",
        "# 3) get a vector (of size 5) of max values between 1) and 2)\n",
        "<YOUR CODE>\n",
        "\n",
        "# 4*) What's the probability of 3) picking a value from 2) rather than 1)? (calculate a Monte-Carlo estimate)\n",
        "<YOUR CODE>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aekHU_RrID5Y",
        "colab_type": "text"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyFR46EdGKPE",
        "colab_type": "text"
      },
      "source": [
        "### CPU vs GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AfdIyrKe72J",
        "colab_type": "text"
      },
      "source": [
        "You can check which device's memory an object is stored in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40aecdlIFH-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.convert_to_tensor([1., 2., 3.])\n",
        "y = tf.convert_to_tensor([3., 2., 1.])\n",
        "z = x[:,tf.newaxis] - y[tf.newaxis,:]\n",
        "\n",
        "print(x.device)\n",
        "print(y.device)\n",
        "print(z.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmd_msVDfMnH",
        "colab_type": "text"
      },
      "source": [
        "In order to check the available devices you can do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzXsRc7vRIj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "for d in device_lib.list_local_devices():\n",
        "  print(d.name, d.device_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHkkkKItgYdb",
        "colab_type": "text"
      },
      "source": [
        "You can explicitly set the device you want to use for a tensor/operation using `tf.devcie(...)` in a python `with` statement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUpVLmkXsnNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  x_gpu = tf.identity(x)\n",
        "print(x.device)\n",
        "print(x_gpu.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfFzq6mzgxC1",
        "colab_type": "text"
      },
      "source": [
        "Let's compare the performance of CPU and GPU with calculating a tensor product of two relatively large vectors. First on CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlGfI6EDFeqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll leave the object creation outside the timimg part\n",
        "with tf.device('/device:CPU:0'):\n",
        "  x = tf.convert_to_tensor(np.arange(10000).astype('float'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxTi1NxrG_cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeit -r1 -n1\n",
        "with tf.device('/device:CPU:0'):\n",
        "  print(tf.reduce_sum(tf.matmul(x[:,tf.newaxis], x[tf.newaxis,:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upDTTfAbhJrF",
        "colab_type": "text"
      },
      "source": [
        "Now same code on GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WerSMXFHUdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  x = tf.convert_to_tensor(np.arange(10000).astype('float'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0chMQ1ZHYNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeit -r1 -n1\n",
        "with tf.device('/device:GPU:0'):\n",
        "  print(tf.reduce_sum(tf.matmul(x[:,tf.newaxis], x[tf.newaxis,:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ZOQ9QfhQF3",
        "colab_type": "text"
      },
      "source": [
        "Note that TensorFlow is smart enought to place tensors and operations on the most efficient devices automatically. E.g. if we create the object on CPU, but then don't specify the device to run computations on, we'll get the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-jMEwOUHmr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device('/device:CPU:0'):\n",
        "  x = tf.convert_to_tensor(np.arange(10000).astype('float'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozotjnd9HofJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeit -r1 -n1\n",
        "print(tf.reduce_sum(tf.matmul(x[:,tf.newaxis], x[tf.newaxis,:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9lKQqs-IG-E",
        "colab_type": "text"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXDZaqcchyX4",
        "colab_type": "text"
      },
      "source": [
        "### Automatic differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhokrhsPh2tt",
        "colab_type": "text"
      },
      "source": [
        "As mentioned earlier, tf can calculate the derivatives for you. This can be done with a `tf.GradientTape` object. This object records the operations of interest to later compute the gradients for:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upou0LhbHr8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.convert_to_tensor(np.linspace(-3, 3, 200))\n",
        "\n",
        "# The operations we need the gradients for should be enclosed\n",
        "# in a `with` statement with `tf.GradientTape`:\n",
        "with tf.GradientTape() as t:\n",
        "  # specify the tensor we'll derive with respect to\n",
        "  t.watch(x)\n",
        "\n",
        "  # do the actual operation:\n",
        "  y = x**2\n",
        "\n",
        "# get the gradient:\n",
        "y_prime = t.gradient(y, x)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(x, y, label='y=x^2')\n",
        "plt.plot(x, y_prime, label='deriv')\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pEA6Ippj6ZK",
        "colab_type": "text"
      },
      "source": [
        "You can nest `tf.GradientTape` contexts to calculate higher order derivatives. Can you figure out the right way to code it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r46cz6bmJDJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.convert_to_tensor(np.linspace(-3, 3, 200))\n",
        "\n",
        "<YOUR CODE>\n",
        "# y = x**3\n",
        "# y_prime - first derivative of y wrt x\n",
        "# y_prime_prime - second derivative of y wrt x\n",
        "\n",
        "plt.plot(x, y, label='y=x^3')\n",
        "plt.plot(x, y_prime, label='deriv')\n",
        "plt.plot(x, y_prime_prime, label='second deriv')\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXenc48tLEK3",
        "colab_type": "text"
      },
      "source": [
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6K2SAJdkQHm",
        "colab_type": "text"
      },
      "source": [
        "### Example: maximum likelihood fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtzG5hC7SCvY",
        "colab_type": "text"
      },
      "source": [
        "Let's generate a Gaussian mixture dataset and then fit its parameters with maximum likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSYk9oqZLDvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = np.random.normal(size=1000, scale=0.3).astype('float32')\n",
        "X2 = np.random.normal(size=2000, loc=5., scale=2.).astype('float32')\n",
        "\n",
        "X = np.concatenate([X1, X2])\n",
        "np.random.shuffle(X)\n",
        "\n",
        "plt.hist(X, bins=200);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0elCyrHLCdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Defining Gaussian PDF using tf functions\n",
        "def gaussian(x, mu, sigma):\n",
        "  <YOUR CODE> # use tf.exp for the exponent, don't forget the normalization\n",
        "\n",
        "# Arbitrary mixture PDF\n",
        "def mixture(x, f1, f2, alpha):\n",
        "  return alpha * f1(x) + (1. - alpha) * f2(x)\n",
        "\n",
        "# Parameters that we'd like to infer (with an initial guess)\n",
        "m1    = tf.Variable(1.0)\n",
        "m2    = tf.Variable(4.0)\n",
        "s1    = tf.Variable(1.0)\n",
        "s2    = tf.Variable(1.0)\n",
        "alpha = tf.Variable(0.5)\n",
        "\n",
        "# At each gradient update we'll apply this function to\n",
        "# ensure valid parameter values\n",
        "def apply_constraints():\n",
        "  <YOUR CODE> # ensure the sigmas are positive and alpha is in (0, 1) interval\n",
        "              # hint: use the `assign` method to update the variable values\n",
        "\n",
        "\n",
        "variables = [m1, m2, s1, s2, alpha]\n",
        "\n",
        "# Defining the overall PDF\n",
        "def model_pdf(x):\n",
        "  return mixture(x,\n",
        "                 lambda t: gaussian(t, m1, s1),\n",
        "                 lambda t: gaussian(t, m2, s2),\n",
        "                 alpha)\n",
        "\n",
        "# Log likelihood\n",
        "def loglike(x):\n",
        "  <YOUR CODE> # hint: the logarithm is in tf.math.log\n",
        "\n",
        "learning_rate = 0.0001\n",
        "grad_history = [] # to keep track of gradient values at different steps\n",
        "\n",
        "for i in range(30):\n",
        "  with tf.GradientTape() as t:\n",
        "    # NOTE: if `variable` was created with `trainable=False`, you need to\n",
        "    # manually add it to the tape by calling `t.watch(variable)`. By default\n",
        "    # the variable are created with `trainable=True`\n",
        "\n",
        "    # Forward pass:\n",
        "    l = loglike(X)\n",
        "  \n",
        "  # Backprop:\n",
        "  grads = <YOUR CODE> # Calculate the gradients\n",
        "  grad_history.append([g.numpy() for g in grads])\n",
        "\n",
        "  # Gradient ascent step:\n",
        "  <YOUR CODE> # Apply the gradients manually (add\n",
        "              # `learning_rate * corresponding_gradient` to\n",
        "              # each variable)\n",
        "  apply_constraints()\n",
        "\n",
        "  ############################\n",
        "  # Do some plotting\n",
        "  plt.figure(figsize=(12, 5))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.hist(X, bins=200, density=True, label='data')\n",
        "  x_grid = np.linspace(-2, 12, 150)\n",
        "  plt.plot(x_grid, model_pdf(x_grid), label='fit')\n",
        "  plt.legend()\n",
        "  plt.xlabel('X')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  lines = plt.plot(np.array(grad_history))\n",
        "  low = min(grad_history[-1])\n",
        "  high = max(grad_history[-1])\n",
        "  plt.ylim(low  - (high - low) * 0.6,\n",
        "           high + (high - low) * 0.6)\n",
        "  plt.legend(lines, ['m1', 'm2', 's1', 's2', 'alpha'])\n",
        "  plt.xlabel('step')\n",
        "  plt.ylabel('gradient')\n",
        "  plt.show()\n",
        "  clear_output(wait=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x6oEkxrXFOz",
        "colab_type": "text"
      },
      "source": [
        "### Example: single hidden layer NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCEb_MThWy-8",
        "colab_type": "text"
      },
      "source": [
        "For this example we'll try to classify some clothes pictures from the Fashion MNIST dataset. We'll use `tensorflow_datasets` to fetch the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJsokZJJR87J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOu9xFGKemS_",
        "colab_type": "text"
      },
      "source": [
        "`tf.data.Dataset` is TensorFlow's abstraction for an arbitrary dataset. It allows building complex loading and processing pipelines by sequentially calling dataset transforming functions.\n",
        "\n",
        "In the code below `tfds.load(...)` returns a `tf.data.Dataset` object, from which we want to load everything at once (`prefetch(number_of_elements)`) and store it in memory (`cache()`). These transformations will be exectuted once we start iterating through the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9bIgzzIXdCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = tfds.load(name=\"fashion_mnist\", split=\"train\").prefetch(60000).cache()\n",
        "data_test  = tfds.load(name=\"fashion_mnist\", split=\"test\" ).prefetch(10000).cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6abnNGR9vc6",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look at the data format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJCeSxa_Xx54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data_train)\n",
        "print(data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISlZK6v3969I",
        "colab_type": "text"
      },
      "source": [
        "So we have images of shape 28 by 28 with a single channel and scalar labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUi5i71q-Fgb",
        "colab_type": "text"
      },
      "source": [
        "Now let's just plot some of the training samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEdmjANRX9lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Array for decoding the categories\n",
        "label_names = np.array(['T-shirt/top',\n",
        "                        'Trouser',\n",
        "                        'Pullover',\n",
        "                        'Dress',\n",
        "                        'Coat',\n",
        "                        'Sandal',\n",
        "                        'Shirt',\n",
        "                        'Sneaker',\n",
        "                        'Bag',\n",
        "                        'Ankle boot'])\n",
        "\n",
        "# Get a single data batch of 25 images\n",
        "sample_data = next(iter(data_train.batch(25)))\n",
        "sample_images = sample_data['image']\n",
        "sample_labels = sample_data['label']\n",
        "\n",
        "# Plot the images in a 5x5 grid\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(\n",
        "    sample_images.numpy().reshape(5, 5, 28, 28).transpose((0, 2, 1, 3)).reshape(140, 140),\n",
        "    cmap='gray'\n",
        ")\n",
        "# Print corresponding labels\n",
        "print(label_names[sample_labels.numpy().reshape(5, 5)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_J-RJFE-ojh",
        "colab_type": "text"
      },
      "source": [
        "Now that we have some idea about the dataset, we are going to define our model. Since we are working with the low-level API, we are going to define all the calculations explicitly. Therefore, we need to explicitly define all the parameters of our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UJbpPG3ZTFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_hidden = 64\n",
        "\n",
        "# Weights and biases of our model.\n",
        "# We'll use He initializtion for weights and zero-initialized biases.\n",
        "w1 = tf.Variable(\n",
        "    np.random.normal(size=(28**2, num_hidden)) * np.sqrt(2. / 28**2),\n",
        "    dtype='float32'\n",
        ")\n",
        "b1 = tf.Variable(np.zeros(shape=(num_hidden,)), dtype='float32')\n",
        "\n",
        "w2 = tf.Variable(\n",
        "    np.random.normal(size=(num_hidden, 10)) * np.sqrt(2. / num_hidden),\n",
        "    dtype='float32'\n",
        ")\n",
        "b2 = tf.Variable(np.zeros(shape=(10,)), dtype='float32')\n",
        "\n",
        "variables = [w1, b1, w2, b2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5ZryRsH_IJb",
        "colab_type": "text"
      },
      "source": [
        "Now the model itself:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SwZxto9kLce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main function of our model.\n",
        "# Given the input images it will return the predicted class probabilites\n",
        "def model(X):\n",
        "  # preprocess the data first\n",
        "  X = tf.reshape((X / 255), (X.shape[0], 28**2))\n",
        "\n",
        "  # First layer\n",
        "  activations1 = <YOUR CODE> # use tf.nn.relu activation\n",
        "\n",
        "  # Second layer\n",
        "  probs = <YOUR CODE> # use tf.nn.softmax activation\n",
        "  return probs\n",
        "\n",
        "# The forward pass: calculate the loss value from a given data batch.\n",
        "def forward(input_batch):\n",
        "  # preprocessing\n",
        "  X = input_batch['image']\n",
        "  y = input_batch['label']\n",
        "  y = tf.reshape(y, (y.shape[0], 1))\n",
        "\n",
        "  probs = model(X)\n",
        "\n",
        "  # Calculate the loss.\n",
        "  cross_entropy_loss = <YOUR CODE>\n",
        "    # Hint: tf.gather_nd(probs, y, batch_dims=1) will collect the probabilities of true classes\n",
        "\n",
        "  return cross_entropy_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1amLLLq8Aztb",
        "colab_type": "text"
      },
      "source": [
        "Now we'll code the main training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHI7QOIKw1CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm # a nice tool to track the progress of a loop\n",
        "import sys\n",
        "\n",
        "# In earlier examples we updated the variables manually.\n",
        "# Actually, a set of ready-to-use tools, called optimizers,\n",
        "# has already been implemented for us.\n",
        "# Here we'll use the Adam optimizer which is a clever\n",
        "# modification of simple stochastic gradient descent.\n",
        "optimizer = tf.optimizers.Adam()\n",
        "batch_size = 1024\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "# variables to keep track of the training history\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# training loop\n",
        "for i_epoch in range(num_epochs):\n",
        "  print(\"Working on epoch #{}\".format(i_epoch))\n",
        "  sys.stdout.flush() # This is to make sure no output is buffered when tqdm is called\n",
        "\n",
        "\n",
        "  # training part\n",
        "  epoch_train_loss = 0\n",
        "  train_samples = 0\n",
        "  for batch in tqdm(data_train.shuffle(60000).batch(batch_size)):\n",
        "    with tf.GradientTape() as t:\n",
        "      loss = <YOUR CODE>\n",
        "    num_samples = len(batch['label'])\n",
        "    epoch_train_loss += loss.numpy() * num_samples\n",
        "    train_samples += num_samples\n",
        "\n",
        "    grads = <YOUR CODE>\n",
        "    optimizer.apply_gradients(zip(grads, variables))\n",
        "  \n",
        "  train_losses.append(epoch_train_loss / train_samples)\n",
        "\n",
        "  # evaluation part\n",
        "  epoch_test_loss = 0\n",
        "  test_samples = 0\n",
        "  for batch in data_test.batch(4096):\n",
        "    epoch_test_loss += forward(batch).numpy() * len(batch['label'])\n",
        "    test_samples += len(batch['label'])\n",
        "  \n",
        "  test_losses.append(epoch_test_loss / test_samples)\n",
        "\n",
        "  # printout and plotting part\n",
        "  clear_output(wait=True)\n",
        "  print(\"Epoch #{}, train loss: {}, test loss: {}\".format(\n",
        "      i_epoch, train_losses[-1], test_losses[-1]\n",
        "  ))\n",
        "  plt.plot(train_losses, label='train')\n",
        "  plt.plot(test_losses , label='test')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v5iSeluCqOg",
        "colab_type": "text"
      },
      "source": [
        "Let's check the accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcpu6ES4uewr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################\n",
        "# Extract the data from the dataset into a numpy array\n",
        "X_batches = []\n",
        "y_batches = []\n",
        "for batch in data_test.batch(4096):\n",
        "  X_batches.append(batch['image'].numpy().astype('float32'))\n",
        "  y_batches.append(batch['label'].numpy())\n",
        "\n",
        "X_test = np.concatenate(X_batches)\n",
        "y_test = np.concatenate(y_batches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rUj8RJySTe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_accuracy(model):\n",
        "  <YOUR CODE> # print out the models accuracy on X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwLuTmpETUGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_accuracy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh1V2oHjC_GA",
        "colab_type": "text"
      },
      "source": [
        "Not too bad. Let's have a look at the wrongly classified objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuaFeuyixse3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model(X_test).numpy().argmax(axis=1)\n",
        "wrong = predictions != y_test\n",
        "print(\"True labels:\")\n",
        "print(label_names[y_test[wrong][:9].reshape(3, 3)])\n",
        "print(\"Predicted labels:\")\n",
        "print(label_names[predictions[wrong][:9].reshape(3, 3)])\n",
        "\n",
        "plt.imshow(\n",
        "  X_test[wrong][:9].reshape(3, 3, 28, 28).transpose(0, 2, 1, 3).reshape(28*3, 28*3)\n",
        ");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43kv6MF9zYdz",
        "colab_type": "text"
      },
      "source": [
        "## High-level API (keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tczZKMcW9Pu",
        "colab_type": "text"
      },
      "source": [
        "### Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLxccpYfDXj0",
        "colab_type": "text"
      },
      "source": [
        "*Quote from https://www.tensorflow.org/guide/keras (see this page for links to mode detailed tutorials):*\n",
        "\n",
        "> `tf.keras` is TensorFlow's high-level API for building and training deep learning models. It's used for fast prototyping, state-of-the-art research, and production, with three key advantages:\n",
        " - **User-friendly**. Keras has a simple, consistent interface optimized for common use cases. It provides clear and actionable feedback for user errors.\n",
        " - **Modular and composable**. Keras models are made by connecting configurable building blocks together, with few restrictions.\n",
        " - **Easy to extend**. Write custom building blocks to express new ideas for research. Create new layers, metrics, loss functions, and develop state-of-the-art models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcPYljSpOIPH",
        "colab_type": "text"
      },
      "source": [
        "Simple feed-forward models with single route from input to output can be built with the `tf.keras.Sequential` model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwziTkDzzb5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  # First layer will do the preprocessing and reshaping of the data (typically\n",
        "  # you want to do this step beforehand, outside of the model, in order to\n",
        "  # increase the performance)\n",
        "  tf.keras.layers.Lambda(\n",
        "      lambda x: tf.reshape(x / 255., (-1, 28*28)),\n",
        "      input_shape=(28, 28, 1), name='preprocessing'\n",
        "  ),\n",
        "\n",
        "  # Densely connected hidden layer\n",
        "  tf.keras.layers.Dense(num_hidden, activation='relu'),\n",
        "\n",
        "  # Output layer (note there's no activation, not even softmax:\n",
        "  # this layer will output logits, there are pre-implemented\n",
        "  # loss functions in `keras` to work with such outputs)\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgXQSuhqPkyx",
        "colab_type": "text"
      },
      "source": [
        "Once your model is built you can print its summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNKnVeQ3_lul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7keIrkBPrEY",
        "colab_type": "text"
      },
      "source": [
        "Keras models can be easily saved and restored. Here's how to save it to hdf5 format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38D_jMo-FyxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('untrained_model.h5', save_format='h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0j2RY4mP3K-",
        "colab_type": "text"
      },
      "source": [
        "Keras models can be used as functions along with the low-level TensorFlow API, such that you can build a fine-tuned training procedure for your needs. However, most of the supervised learning processes fall into the same routine that has been conveniently pre-implemented in `keras`. In order to use it you want to \"compile\" your model. That is, assign it an optimizer, a loss function and optionally some validation metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yRhMgFE38R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu_Ar6NQQ5cU",
        "colab_type": "text"
      },
      "source": [
        "Once the model is compiled, you can run the training loop using the `fit` method (alternatively, `fit_generator`, see the docs for more info), which can work with different data formats, including tensorflow datasets.\n",
        "\n",
        "Since our dataset is structured (it has inputs and targets labeled with the 'image' and 'label' keys), we want to convert it to a dataset of tuples `(input, target)`. We'll do that with the `tf.data.Dataset.map` method and the following convertion function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0vvlCG6y3J-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unwrap(x):\n",
        "  return (x['image'], x['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjAfI5O8SKBc",
        "colab_type": "text"
      },
      "source": [
        "And finally run the training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCmvLnea5Hhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x=data_train.map(unwrap).shuffle(60000).batch(batch_size),\n",
        "          epochs=10,\n",
        "          validation_data=data_test.map(unwrap).batch(4096))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bScmIgggSOTj",
        "colab_type": "text"
      },
      "source": [
        "Let's save the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgHUuuz2GfaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('trained_model.h5', save_format='h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPwvQN3_SdBq",
        "colab_type": "text"
      },
      "source": [
        "We can now check the accuracy of the model. Let's compare it before and after the training by loading the saved weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hd8K9hQ6PU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('untrained_model.h5')\n",
        "check_accuracy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftkZnR2T61MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('trained_model.h5')\n",
        "check_accuracy(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLdU5reWUMub",
        "colab_type": "text"
      },
      "source": [
        "Note that we were saving not just the weights, but the entire model (with the computation graph). This means we can load the entire model without having to specify it's architecture:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrJBm2ZgMIq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_accuracy(tf.keras.models.load_model('trained_model.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V63F0QyFXDp0",
        "colab_type": "text"
      },
      "source": [
        "### Validation metrics and callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5-uuQkAUfpM",
        "colab_type": "text"
      },
      "source": [
        "Now, let's get back to the untrained state of our model and add some more useful tools to the training process. Earlier we mentined that you can add validation metrics to you model. Here's how its done:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5AKPulMJ1pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('untrained_model.h5')\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[tf.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svy8EBgvUy10",
        "colab_type": "text"
      },
      "source": [
        "Another useful thing is keras callbacks - these are function objects to be called at specific events (e.g. at end of batch or epoch processing, etc.).\n",
        "\n",
        "One of such callbacks can automatically save our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4a0qXuP2jAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This callback will save the model every 5 epochs:\n",
        "saver1 = tf.keras.callbacks.ModelCheckpoint(filepath='model_epoch_{epoch:02d}.h5',\n",
        "                                            save_freq=5 * 60000)\n",
        "\n",
        "# This one will save only the best model based on the validation metric (accuracy):\n",
        "saver2 = tf.keras.callbacks.ModelCheckpoint(filepath='model_best.h5',\n",
        "                                            monitor='val_sparse_categorical_accuracy',\n",
        "                                            save_best_only=True)\n",
        "\n",
        "# We need to provide these callbacks to the `callbacks` argument of the `fit` method:\n",
        "model.fit(x=data_train.map(unwrap).shuffle(60000).batch(batch_size),\n",
        "          epochs=30,\n",
        "          validation_data=data_test.map(unwrap).batch(4096),\n",
        "          callbacks=[saver1, saver2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgWcYo8bNk6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = tf.keras.models.load_model('model_best.h5')\n",
        "predictions = loaded_model(X_test).numpy().argmax(axis=1)\n",
        "print(\"Test accuracy is:\", (predictions == y_test).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARTAPmYVXLBl",
        "colab_type": "text"
      },
      "source": [
        "### Training history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-WtTWdcVwYJ",
        "colab_type": "text"
      },
      "source": [
        "After the `fit` method was called, a history object is attached to the model. This can be used to check how various metrics behaved during the training process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYWBTsBUOnif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(model.history.history['loss']    , label='train_loss')\n",
        "plt.plot(model.history.history['val_loss'], label='test_loss')\n",
        "\n",
        "plt.plot(model.history.history['sparse_categorical_accuracy'    ], label='train accuracy')\n",
        "plt.plot(model.history.history['val_sparse_categorical_accuracy'], label='test accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('cross entropy / test accuracy')\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVTJv73lXP5j",
        "colab_type": "text"
      },
      "source": [
        "## Miscellaneous: hidden layer activations / ideal ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNAIAr4pWfEI",
        "colab_type": "text"
      },
      "source": [
        "Now let's have a look at what features are being extracted by the hidden layer of the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDEQuAXhK-e1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('model_best.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ioKHu2R2OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "hidden_weights = model.layers[1].weights[0].numpy()\n",
        "hidden_weights /= (hidden_weights**2).sum(axis=0)**0.5\n",
        "\n",
        "plt.imshow(hidden_weights.T.reshape(8, 8, 28, 28).transpose(0, 2, 1, 3).reshape(28*8, 28*8), cmap='gray');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blEwK6juhgmi",
        "colab_type": "text"
      },
      "source": [
        "Here we create a random image and then optimize it to maximize the prediction for a given category:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN4siAa9ZLfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEqilWphWdPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = tf.Variable(np.random.normal(size=(1, 28*28)), dtype='float32')\n",
        "category = 9\n",
        "\n",
        "# Category legend:\n",
        "# 0 - 'T-shirt/top',\n",
        "# 1 - 'Trouser',\n",
        "# 2 - 'Pullover',\n",
        "# 3 - 'Dress',\n",
        "# 4 - 'Coat',\n",
        "# 5 - 'Sandal',\n",
        "# 6 - 'Shirt',\n",
        "# 7 - 'Sneaker',\n",
        "# 8 - 'Bag',\n",
        "# 9 - 'Ankle boot'\n",
        "\n",
        "for i in range(1000):\n",
        "  with tf.GradientTape() as t:\n",
        "    predictions = model.layers[2](model.layers[1](img))\n",
        "    score = tf.reduce_min(predictions[:,category:category+1] - \n",
        "                          tf.concat([predictions[:,:category],\n",
        "                                     predictions[:,category+1:]], axis=1),\n",
        "                          axis=1)\n",
        "\n",
        "  grads = t.gradient(score, img)\n",
        "  img.assign_add(0.01 * grads)\n",
        "  img.assign(img - tf.reduce_min(img, keepdims=True))\n",
        "  img.assign(img / tf.reduce_max(img))\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    clear_output(wait=True)\n",
        "    plt.imshow(img.numpy().reshape(28, 28), cmap='gray');\n",
        "    plt.show();\n",
        "    time.sleep(0.2)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-mZGsl_X0Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = (255 * img.numpy())\n",
        "\n",
        "model(img.reshape(1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RvUvGgGrkzv",
        "colab_type": "text"
      },
      "source": [
        "## Excercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXYu5ujhrowp",
        "colab_type": "text"
      },
      "source": [
        "### Ex. 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCujyYCdrrrg",
        "colab_type": "text"
      },
      "source": [
        "Move the preprocessing part out of the model into the dataset pipeline (using the `map` method)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gIkK_1Gr-mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYp5xgozr0GG",
        "colab_type": "text"
      },
      "source": [
        "### Ex. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_kVluKKr2uM",
        "colab_type": "text"
      },
      "source": [
        "Train a model with more layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxRpoyi_rnnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kUYwTIxr_XX",
        "colab_type": "text"
      },
      "source": [
        "### Ex. 3*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d22MrR2sBFE",
        "colab_type": "text"
      },
      "source": [
        "Train a model which is an average of two models with different numbers of layers.\n",
        "You can:\n",
        " - either use low-level API for that (still using `tf.keras.Sequential` models as building blocks)\n",
        " - or use `tf.keras.Model` for an arbitrary model (see the very first example from https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLUIX7ozsAfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}